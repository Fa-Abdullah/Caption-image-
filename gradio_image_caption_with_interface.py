# -*- coding: utf-8 -*-
"""Gradio image caption with interface.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gTYmxYtdeyjycc654dn5UEphyj-qGOBs
"""

!pip install gradio

"""#Creating Gradio Interface"""

import gradio as gr
def greet(name, intensity):
  return "Hello, " + name + "!" * int(intensity)
demo = gr.Interface(
  fn=greet,
  inputs=["text", "slider"],
  outputs=["text"],
)
demo.launch(server_name="127.0.0.1")

"""#*BLIP APP*"""

!pip install transformers
!pip install torch

import gradio as gr
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import torch

processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

def generate_caption(image):
  inputs = processor(images=image, return_tensors="pt")
  outputs = model.generate(**inputs)
  caption = processor.decode(outputs[0], skip_special_tokens=True)
  return caption

def caption_image(image):
  try:
        caption = generate_caption(image)
        return caption
  except Exception as e:
        return f"An error occurred: {str(e)}"

iface = gr.Interface(
    fn=caption_image,
    inputs=gr.Image(type="pil"),
    outputs="text",
    title="Image Captioning",
    description="Upload an image and get a caption.",
)

iface.launch(server_name="127.0.0.1", debug=True)

"""#Image Classification PyTorch"""

import torch
model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()

import requests
from PIL import Image
from torchvision import transforms

# Download human-readable labels for ImageNet
response = requests.get("https://git.io/JJkYN")
labels = response.text.split("\n")

def predict(inp):
  inp = transforms.ToTensor()(inp).unsqueeze(0)
  with torch.no_grad():
    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)
    confidences = {
      labels[i]: float(prediction[i])
      for i in range(1000)
    }
    return confidences

import gradio as gr
gr.Interface(
  fn=predict,
  inputs=gr.Image(type="pil"),
  outputs=gr.Label(num_top_classes=3),
  examples=["/content/lion.jpg", "/content/cheetah.jpg"]).launch()

